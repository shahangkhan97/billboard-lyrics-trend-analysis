{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📘 Notebook Summary – 01_Data_Collection.ipynb\n",
        "This notebook is the data collection pipeline for a broader music analytics project. It automates the process of gathering Billboard Hot 100 songs from 1959 to 2024, along with their lyrics, by combining web scraping and asynchronous API requests. The workflow is designed for performance, maintainability, and scalability.\n",
        "\n",
        "## Key Features:\n",
        "* **Chart Scraping:** Scrapes the Billboard Year-End Hot 100 list for each year using Wikipedia.\n",
        "\n",
        "* **Async Lyrics Fetching:** Uses aiohttp to fetch lyrics from the lyrics.ovh API with intelligent title/artist variations and retry logic to maximize success rate.\n",
        "\n",
        "* **Caching System:** Implements a JSON-based caching mechanism to avoid redundant API calls and improve performance across sessions.\n",
        "\n",
        "* **Error Handling & Logging:** Gracefully handles missing data and logs failed entries for analysis.\n",
        "\n",
        "* **Modular Functions:** Functions are clearly organized by role (scraping, cleaning, API calls, caching, orchestration), making the code reusable and extensible.\n",
        "\n",
        "This notebook sets the foundation for subsequent analysis — including sentiment, word frequency, topic modeling, and visual storytelling based on lyrics trends."
      ],
      "metadata": {
        "id": "zAwkvqezUj0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📦 Imports & Setup\n",
        "\n",
        "This section imports all the essential libraries used throughout the notebook:\n",
        "\n",
        "* **Web Scraping & Requests**: requests, BeautifulSoup – to scrape Billboard Hot 100 chart data from Wikipedia.\n",
        "\n",
        "* **Async I/O & Networking**: aiohttp, asyncio, nest_asyncio – to enable asynchronous fetching of lyrics from an API for improved performance in a Jupyter environment.\n",
        "\n",
        "* **Data Handling**: pandas, numpy, json, os – for efficient data manipulation, caching, and storage.\n",
        "\n",
        "* **Text Processing & NLP**: re, nltk, TextBlob, WordNetLemmatizer, stopwords – for cleaning, tokenizing, and analyzing song lyrics.\n",
        "\n",
        "* **Visualization**: matplotlib, seaborn, WordCloud – to visualize insights such as most common words and trends.\n",
        "\n",
        "* **Utility**: tqdm.asyncio – for progress bars in asynchronous loops, and logging for monitoring execution.\n",
        "\n",
        "* **nest_asyncio.apply**() is called to allow nested event loops for Google Colab, enabling smooth use of asyncio.run() inside the notebook."
      ],
      "metadata": {
        "id": "aOzH4-VHPHER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmr5GhArO-Hv"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import re\n",
        "import urllib.parse\n",
        "import time\n",
        "import logging\n",
        "from tqdm.asyncio import tqdm_asyncio\n",
        "import nest_asyncio\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "from nltk import ngrams\n",
        "import zipfile\n",
        "\n",
        "# Applying nest_asyncio for notebook compatibility\n",
        "nest_asyncio.apply()\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating function to scrape data from Billboard hot-100 year end pages on wikipedia\n",
        "\n",
        "The function parses the HTML table on the wikipedia page using ***BeautifulSoup***, handles cases where artist names are omitted due to rowspans (if consecutive songs have the same artist), and returns a clean pandas DataFrame with the song's rank, title, and artist."
      ],
      "metadata": {
        "id": "gVThxh7LPfK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# WEB SCRAPING FUNCTIONS\n",
        "# --------------------------\n",
        "\n",
        "def scrape_hot_100(year):\n",
        "    \"\"\"Scrape Billboard Hot 100 for given year\"\"\"\n",
        "    url = f\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{year}\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching {year}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "    if table is None:\n",
        "        logging.warning(f\"Hot 100 table not found for {year}\")\n",
        "        return None\n",
        "\n",
        "    data = []\n",
        "    current_artist = None\n",
        "\n",
        "    for row in table.find_all('tr')[1:]:  # Skip header\n",
        "        cols = row.find_all('td')\n",
        "\n",
        "        if len(cols) == 3:  # Full row with artist\n",
        "            try:\n",
        "                rank = int(cols[0].text.strip())\n",
        "                title = cols[1].text.strip().strip('\"')\n",
        "                current_artist = cols[2].text.strip()\n",
        "                data.append([rank, title, current_artist])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        elif len(cols) == 2 and current_artist:  # Rowspan artist case\n",
        "            try:\n",
        "                rank = int(cols[0].text.strip())\n",
        "                title = cols[1].text.strip().strip('\"')\n",
        "                data.append([rank, title, current_artist])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    if not data:\n",
        "        return None\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Rank\", \"Title\", \"Artist\"])\n",
        "    return df.set_index(\"Rank\")\n"
      ],
      "metadata": {
        "id": "8TBEL-z0PeKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎵 Lyric Fetching Functions\n",
        "\n",
        "This section defines asynchronous functions to fetch song lyrics from the lyrics.ovh API ( [website](https://lyricsovh.docs.apiary.io/#) / [github](https://github.com/NTag/lyrics.ovh)). It includes:\n",
        "\n",
        "\n",
        "\n",
        "*   **clean_artist_name()**: Cleans artist names by removing extra punctuation, featured artists, and brackets to improve match accuracy.\n",
        "\n",
        "*   **fetch_lyrics()**: Sends asynchronous API requests to retrieve lyrics for a given artist and song title.\n",
        "\n",
        "*   **fetch_with_retries()**: Tries multiple variations of artist and song title combinations to maximize the chance of a successful match, with optional retries and delays for robustness.\n",
        "\n",
        "These functions work together to collect lyrics data while handling naming inconsistencies common in music metadata."
      ],
      "metadata": {
        "id": "wze1QpufQUsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# LYRIC FETCHING FUNCTIONS\n",
        "# --------------------------\n",
        "\n",
        "def clean_artist_name(artist):\n",
        "    \"\"\"Optimized artist cleaning function\"\"\"\n",
        "    if not isinstance(artist, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove content in parentheses and brackets\n",
        "    artist = re.sub(r'\\([^)]*\\)|\\[[^\\]]*\\]', '', artist)\n",
        "\n",
        "    # Handle common patterns with a single regex\n",
        "    match = re.search(r'^([^,;&/]+?)(?:\\s*(?:,|&|and|featuring?|ft\\.?|with|/|x)\\s|$)', artist, flags=re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else artist.strip()\n",
        "\n",
        "async def fetch_lyrics(session, artist, title, timeout=8):\n",
        "    \"\"\"Fetch lyrics with optimized parameters\"\"\"\n",
        "    artist_encoded = urllib.parse.quote(artist)\n",
        "    title_encoded = urllib.parse.quote(title)\n",
        "    url = f\"https://api.lyrics.ovh/v1/{artist_encoded}/{title_encoded}\"\n",
        "\n",
        "    try:\n",
        "        async with session.get(url, timeout=timeout) as response:\n",
        "            if response.status == 200:\n",
        "                data = await response.json()\n",
        "                return data.get('lyrics', '')\n",
        "            elif response.status == 404:\n",
        "                return ''  # Known missing\n",
        "    except (aiohttp.ClientError, asyncio.TimeoutError):\n",
        "        return ''\n",
        "    return ''\n",
        "\n",
        "async def fetch_with_retries(session, artist, title, max_retries=3):\n",
        "    \"\"\"Optimized with precomputed variations\"\"\"\n",
        "    # Clean artist name once\n",
        "    primary_artist = clean_artist_name(artist)\n",
        "\n",
        "    # Precompute title variations\n",
        "    base_title = re.sub(r'\\([^)]*\\)', '', title).strip()\n",
        "    base_title_no_punct = re.sub(r'[\\!\\?\\.\\,\\']', '', base_title)\n",
        "    base_title_no_feat = title.split(' (')[0].strip()\n",
        "\n",
        "    # Prepare all variations upfront\n",
        "    variations = [\n",
        "        (primary_artist, title),\n",
        "        (primary_artist, base_title),\n",
        "        (primary_artist, base_title_no_feat),\n",
        "        (artist.split(',')[0].strip(), title),\n",
        "        (artist, title),\n",
        "        (primary_artist, f\"{base_title} (feat. ...)\"),\n",
        "        (primary_artist, base_title_no_punct),\n",
        "    ]\n",
        "\n",
        "    # Add extra variations for problematic titles\n",
        "    if any(char in title for char in ['!', '?', '.', ',', \"'\"]):\n",
        "        variations.append((artist, base_title_no_punct))\n",
        "        variations.append((primary_artist, base_title_no_punct))\n",
        "\n",
        "    # Try variations without delay first\n",
        "    for try_artist, try_title in variations[:max_retries]:\n",
        "        lyrics = await fetch_lyrics(session, try_artist, try_title)\n",
        "        if lyrics:\n",
        "            return lyrics\n",
        "\n",
        "    # Add delays only for remaining retries\n",
        "    for i, (try_artist, try_title) in enumerate(variations[max_retries:max_retries*2]):\n",
        "        await asyncio.sleep(0.2 * (i + 1))\n",
        "        lyrics = await fetch_lyrics(session, try_artist, try_title)\n",
        "        if lyrics:\n",
        "            return lyrics\n",
        "\n",
        "    return ''"
      ],
      "metadata": {
        "id": "x-y9LeiXTYip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##💾 Lyrics Caching System\n",
        "This class implements a JSON-based cache to store and reuse fetched lyrics, reducing redundant API calls and improving efficiency. Key features include:\n",
        "\n",
        "*   Persistent storage in lyrics_cache.json.\n",
        "\n",
        "*   Efficient lookup using normalized artist and song title keys.\n",
        "\n",
        "*   Periodic auto-saving every 50 entries to avoid frequent file I/O.\n",
        "\n",
        "This helps speed up lyric retrieval in repeated or large-scale scraping runs."
      ],
      "metadata": {
        "id": "rf2Rx937TZoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# CACHE SYSTEM FOR REUSABLE RESULTS\n",
        "# --------------------------\n",
        "\n",
        "class LyricsCache:\n",
        "    def __init__(self, cache_file='lyrics_cache.json'):\n",
        "        self.cache_file = cache_file\n",
        "        self.cache = self.load_cache()\n",
        "\n",
        "    def load_cache(self):\n",
        "        if os.path.exists(self.cache_file):\n",
        "            try:\n",
        "                with open(self.cache_file, 'r') as f:\n",
        "                    return json.load(f)\n",
        "            except:\n",
        "                return {}\n",
        "        return {}\n",
        "\n",
        "    def save_cache(self):\n",
        "        with open(self.cache_file, 'w') as f:\n",
        "            json.dump(self.cache, f)\n",
        "\n",
        "    def get_key(self, artist, title):\n",
        "        return f\"{clean_artist_name(artist)}|||{title.lower().strip()}\"\n",
        "\n",
        "    def get(self, artist, title):\n",
        "        return self.cache.get(self.get_key(artist, title), None)\n",
        "\n",
        "    def set(self, artist, title, lyrics):\n",
        "        key = self.get_key(artist, title)\n",
        "        self.cache[key] = lyrics\n",
        "        # Save periodically rather than on every set\n",
        "        if len(self.cache) % 50 == 0:\n",
        "            self.save_cache()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cache)"
      ],
      "metadata": {
        "id": "hqG7CsRBThGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ Optimized Main Execution Pipeline\n",
        "This section orchestrates the full scraping and lyric-fetching workflow across multiple years of Billboard Hot 100 data. Key features include:\n",
        "\n",
        "### process_year():\n",
        "\n",
        "*   Scrapes chart data for a given year.\n",
        "\n",
        "*   Retrieves cached lyrics where available.\n",
        "\n",
        "*   Uses asynchronous batch requests to fetch missing lyrics concurrently.\n",
        "\n",
        "*   Writes results to a CSV file and logs any failed fetches.\n",
        "\n",
        "### main():\n",
        "\n",
        "*   Coordinates the end-to-end process for multiple years.\n",
        "\n",
        "*   Manages connection pooling via aiohttp for performance.\n",
        "\n",
        "*   Persists the lyrics cache and logs missing entries for later review.\n",
        "\n",
        "\n",
        "The workflow is designed for speed and efficiency, using async I/O, intelligent caching, and batch processing to handle large-scale data collection and enrichment."
      ],
      "metadata": {
        "id": "TggjriorSXeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# OPTIMIZED MAIN EXECUTION\n",
        "# --------------------------\n",
        "\n",
        "async def process_year(year, cache, session, concurrency=50):\n",
        "    \"\"\"Process a single year with caching and optimized fetching\"\"\"\n",
        "    print(f\"\\n{'='*40}\\nProcessing {year}\\n{'='*40}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Scrape Billboard data\n",
        "    billboard_df = scrape_hot_100(year)\n",
        "    if billboard_df is None:\n",
        "        print(f\"⚠️  No data found for {year}\")\n",
        "        return None, []\n",
        "\n",
        "    print(f\"Found {len(billboard_df)} songs for {year}\")\n",
        "\n",
        "    # Initialize lyrics column\n",
        "    billboard_df['Lyrics'] = ''\n",
        "\n",
        "    # Check cache first\n",
        "    cached_count = 0\n",
        "    for idx, row in billboard_df.iterrows():\n",
        "        cache_key = cache.get_key(row['Artist'], row['Title'])\n",
        "        if cache_key in cache.cache:\n",
        "            billboard_df.at[idx, 'Lyrics'] = cache.cache[cache_key]\n",
        "            cached_count += 1\n",
        "\n",
        "    print(f\"🚀 {cached_count}/{len(billboard_df)} lyrics from cache\")\n",
        "\n",
        "    # Prepare tasks for missing lyrics\n",
        "    tasks = []\n",
        "    for idx, row in billboard_df.iterrows():\n",
        "        if not billboard_df.at[idx, 'Lyrics']:\n",
        "            tasks.append(\n",
        "                fetch_with_retries(session, row['Artist'], row['Title'])\n",
        "            )\n",
        "\n",
        "    # Process in batches for better memory management\n",
        "    results = []\n",
        "    batch_size = concurrency * 5  # Process in larger batches\n",
        "    for i in range(0, len(tasks), batch_size):\n",
        "        batch = tasks[i:i+batch_size]\n",
        "        batch_results = await tqdm_asyncio.gather(\n",
        "            *batch,\n",
        "            desc=f\"Fetching {year} lyrics\",\n",
        "            unit=\"song\"\n",
        "        )\n",
        "        results.extend(batch_results)\n",
        "\n",
        "    # Update DataFrame and cache\n",
        "    result_idx = 0\n",
        "    failed_entries = []\n",
        "    for idx, row in billboard_df.iterrows():\n",
        "        if not billboard_df.at[idx, 'Lyrics']:\n",
        "            lyrics = results[result_idx]\n",
        "            result_idx += 1\n",
        "\n",
        "            if lyrics:\n",
        "                billboard_df.at[idx, 'Lyrics'] = lyrics\n",
        "                cache.set(row['Artist'], row['Title'], lyrics)\n",
        "            else:\n",
        "                failed_entries.append({\n",
        "                    'Year': year,\n",
        "                    'Artist': row['Artist'],\n",
        "                    'Title': row['Title'],\n",
        "                    'Rank': idx\n",
        "                })\n",
        "\n",
        "    # Save results\n",
        "    billboard_df.to_csv(f\"hot100_{year}.csv\")\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"✅ Saved {year} data in {elapsed:.1f}s - {len(failed_entries)} missing\")\n",
        "\n",
        "    return billboard_df, failed_entries\n",
        "\n",
        "async def main(years, concurrency=30):\n",
        "    \"\"\"Run the full scraping process with caching and concurrency\"\"\"\n",
        "    cache = LyricsCache()\n",
        "    all_data = {}\n",
        "    all_failed_entries = []\n",
        "\n",
        "    # Reusable HTTP session with connection pooling\n",
        "    connector = aiohttp.TCPConnector(limit=concurrency)\n",
        "    async with aiohttp.ClientSession(connector=connector) as session:\n",
        "        for year in years:\n",
        "            try:\n",
        "                df, failed = await process_year(year, cache, session, concurrency)\n",
        "                if df is not None:\n",
        "                    all_data[year] = df\n",
        "                    all_failed_entries.extend(failed)\n",
        "            except Exception as e:\n",
        "                print(f\"🚨 Critical error processing {year}: {str(e)}\")\n",
        "                logging.exception(e)\n",
        "\n",
        "    # Final cache save\n",
        "    cache.save_cache()\n",
        "\n",
        "    # Save failure log\n",
        "    if all_failed_entries:\n",
        "        fail_df = pd.DataFrame(all_failed_entries)\n",
        "        fail_df.to_csv('missing_lyrics_log.csv', index=False)\n",
        "        print(f\"\\nSaved {len(fail_df)} missing entries to log\")\n",
        "\n",
        "    return all_data\n",
        "\n",
        "# Run on Colab\n",
        "if __name__ == \"__main__\":\n",
        "    # Years to process\n",
        "    years_to_scrape = list(range(1959, 2025))\n",
        "\n",
        "    # Run with high concurrency\n",
        "    hot_100_data = asyncio.run(main(years_to_scrape, concurrency=40))\n",
        "\n",
        "    # Show summary\n",
        "    for year, df in hot_100_data.items():\n",
        "        missing = df[df['Lyrics'] == '']\n",
        "        print(f\"{year}: {len(missing)} missing lyrics\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C42GOycP_0B",
        "outputId": "394b9127-defc-4fde-fdf0-109d7cadf8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Processing 1959\n",
            "========================================\n",
            "Found 100 songs for 1959\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1959 lyrics: 100%|██████████| 100/100 [00:11<00:00,  8.58song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1959 data in 11.9s - 42 missing\n",
            "\n",
            "========================================\n",
            "Processing 1960\n",
            "========================================\n",
            "Found 100 songs for 1960\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1960 lyrics: 100%|██████████| 99/99 [00:08<00:00, 11.67song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1960 data in 8.7s - 36 missing\n",
            "\n",
            "========================================\n",
            "Processing 1961\n",
            "========================================\n",
            "Found 100 songs for 1961\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1961 lyrics: 100%|██████████| 100/100 [00:07<00:00, 12.70song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1961 data in 8.0s - 29 missing\n",
            "\n",
            "========================================\n",
            "Processing 1962\n",
            "========================================\n",
            "Found 100 songs for 1962\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1962 lyrics: 100%|██████████| 99/99 [00:08<00:00, 12.22song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1962 data in 8.6s - 29 missing\n",
            "\n",
            "========================================\n",
            "Processing 1963\n",
            "========================================\n",
            "Found 100 songs for 1963\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1963 lyrics: 100%|██████████| 100/100 [00:11<00:00,  9.02song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1963 data in 11.3s - 42 missing\n",
            "\n",
            "========================================\n",
            "Processing 1964\n",
            "========================================\n",
            "Found 100 songs for 1964\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1964 lyrics: 100%|██████████| 100/100 [00:10<00:00,  9.39song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1964 data in 10.9s - 40 missing\n",
            "\n",
            "========================================\n",
            "Processing 1965\n",
            "========================================\n",
            "Found 100 songs for 1965\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1965 lyrics: 100%|██████████| 100/100 [00:08<00:00, 11.21song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1965 data in 9.1s - 29 missing\n",
            "\n",
            "========================================\n",
            "Processing 1966\n",
            "========================================\n",
            "Found 100 songs for 1966\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1966 lyrics: 100%|██████████| 100/100 [00:09<00:00, 10.12song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1966 data in 10.1s - 42 missing\n",
            "\n",
            "========================================\n",
            "Processing 1967\n",
            "========================================\n",
            "Found 100 songs for 1967\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1967 lyrics: 100%|██████████| 100/100 [00:09<00:00, 10.83song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1967 data in 9.6s - 33 missing\n",
            "\n",
            "========================================\n",
            "Processing 1968\n",
            "========================================\n",
            "Found 100 songs for 1968\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1968 lyrics: 100%|██████████| 100/100 [00:08<00:00, 11.92song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1968 data in 8.6s - 31 missing\n",
            "\n",
            "========================================\n",
            "Processing 1969\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-57c07e56214c>\", line 88, in main\n",
            "    df, failed = await process_year(year, cache, session, concurrency)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-10-57c07e56214c>\", line 34, in process_year\n",
            "    if not billboard_df.at[idx, 'Lyrics']:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\", line 1577, in __nonzero__\n",
            "    raise ValueError(\n",
            "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "<ipython-input-10-57c07e56214c>:94: RuntimeWarning: coroutine 'fetch_with_retries' was never awaited\n",
            "  logging.exception(e)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 101 songs for 1969\n",
            "🚀 0/101 lyrics from cache\n",
            "🚨 Critical error processing 1969: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
            "\n",
            "========================================\n",
            "Processing 1970\n",
            "========================================\n",
            "Found 100 songs for 1970\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1970 lyrics: 100%|██████████| 100/100 [00:09<00:00, 10.60song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1970 data in 9.6s - 32 missing\n",
            "\n",
            "========================================\n",
            "Processing 1971\n",
            "========================================\n",
            "Found 100 songs for 1971\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1971 lyrics: 100%|██████████| 100/100 [00:12<00:00,  7.75song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1971 data in 13.2s - 42 missing\n",
            "\n",
            "========================================\n",
            "Processing 1972\n",
            "========================================\n",
            "Found 100 songs for 1972\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1972 lyrics: 100%|██████████| 100/100 [00:09<00:00, 10.04song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1972 data in 10.2s - 31 missing\n",
            "\n",
            "========================================\n",
            "Processing 1973\n",
            "========================================\n",
            "Found 100 songs for 1973\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1973 lyrics: 100%|██████████| 100/100 [00:10<00:00,  9.53song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1973 data in 10.7s - 28 missing\n",
            "\n",
            "========================================\n",
            "Processing 1974\n",
            "========================================\n",
            "Found 100 songs for 1974\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1974 lyrics: 100%|██████████| 100/100 [00:09<00:00, 10.88song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1974 data in 9.4s - 22 missing\n",
            "\n",
            "========================================\n",
            "Processing 1975\n",
            "========================================\n",
            "Found 100 songs for 1975\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1975 lyrics: 100%|██████████| 100/100 [00:08<00:00, 11.90song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1975 data in 8.6s - 28 missing\n",
            "\n",
            "========================================\n",
            "Processing 1976\n",
            "========================================\n",
            "Found 100 songs for 1976\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1976 lyrics: 100%|██████████| 99/99 [00:07<00:00, 13.57song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1976 data in 7.7s - 20 missing\n",
            "\n",
            "========================================\n",
            "Processing 1977\n",
            "========================================\n",
            "Found 100 songs for 1977\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1977 lyrics: 100%|██████████| 100/100 [00:07<00:00, 12.51song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1977 data in 8.2s - 22 missing\n",
            "\n",
            "========================================\n",
            "Processing 1978\n",
            "========================================\n",
            "Found 100 songs for 1978\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1978 lyrics: 100%|██████████| 100/100 [00:06<00:00, 15.52song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1978 data in 6.6s - 10 missing\n",
            "\n",
            "========================================\n",
            "Processing 1979\n",
            "========================================\n",
            "Found 100 songs for 1979\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1979 lyrics: 100%|██████████| 99/99 [00:06<00:00, 15.07song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1979 data in 6.8s - 23 missing\n",
            "\n",
            "========================================\n",
            "Processing 1980\n",
            "========================================\n",
            "Found 100 songs for 1980\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1980 lyrics: 100%|██████████| 100/100 [00:06<00:00, 14.64song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1980 data in 7.0s - 22 missing\n",
            "\n",
            "========================================\n",
            "Processing 1981\n",
            "========================================\n",
            "Found 100 songs for 1981\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1981 lyrics: 100%|██████████| 100/100 [00:07<00:00, 13.80song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1981 data in 7.4s - 21 missing\n",
            "\n",
            "========================================\n",
            "Processing 1982\n",
            "========================================\n",
            "Found 100 songs for 1982\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1982 lyrics: 100%|██████████| 99/99 [00:06<00:00, 14.77song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1982 data in 6.9s - 24 missing\n",
            "\n",
            "========================================\n",
            "Processing 1983\n",
            "========================================\n",
            "Found 100 songs for 1983\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1983 lyrics: 100%|██████████| 99/99 [00:06<00:00, 15.80song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1983 data in 6.6s - 10 missing\n",
            "\n",
            "========================================\n",
            "Processing 1984\n",
            "========================================\n",
            "Found 100 songs for 1984\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1984 lyrics: 100%|██████████| 100/100 [00:06<00:00, 14.72song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1984 data in 7.0s - 15 missing\n",
            "\n",
            "========================================\n",
            "Processing 1985\n",
            "========================================\n",
            "Found 100 songs for 1985\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1985 lyrics: 100%|██████████| 100/100 [00:06<00:00, 15.76song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1985 data in 6.6s - 15 missing\n",
            "\n",
            "========================================\n",
            "Processing 1986\n",
            "========================================\n",
            "Found 100 songs for 1986\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1986 lyrics: 100%|██████████| 100/100 [00:06<00:00, 15.63song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1986 data in 6.6s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 1987\n",
            "========================================\n",
            "Found 100 songs for 1987\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1987 lyrics: 100%|██████████| 99/99 [00:06<00:00, 15.93song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1987 data in 6.4s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 1988\n",
            "========================================\n",
            "Found 100 songs for 1988\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1988 lyrics: 100%|██████████| 100/100 [00:06<00:00, 16.27song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1988 data in 6.3s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 1989\n",
            "========================================\n",
            "Found 100 songs for 1989\n",
            "🚀 0/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1989 lyrics: 100%|██████████| 100/100 [00:06<00:00, 16.63song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1989 data in 6.3s - 12 missing\n",
            "\n",
            "========================================\n",
            "Processing 1990\n",
            "========================================\n",
            "Found 100 songs for 1990\n",
            "🚀 2/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1990 lyrics: 100%|██████████| 98/98 [00:06<00:00, 15.84song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1990 data in 6.7s - 8 missing\n",
            "\n",
            "========================================\n",
            "Processing 1991\n",
            "========================================\n",
            "Found 100 songs for 1991\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1991 lyrics: 100%|██████████| 99/99 [00:06<00:00, 14.39song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1991 data in 7.1s - 16 missing\n",
            "\n",
            "========================================\n",
            "Processing 1992\n",
            "========================================\n",
            "Found 100 songs for 1992\n",
            "🚀 1/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1992 lyrics: 100%|██████████| 99/99 [00:05<00:00, 17.62song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1992 data in 5.8s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 1993\n",
            "========================================\n",
            "Found 100 songs for 1993\n",
            "🚀 3/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1993 lyrics: 100%|██████████| 97/97 [00:06<00:00, 15.09song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1993 data in 6.6s - 18 missing\n",
            "\n",
            "========================================\n",
            "Processing 1994\n",
            "========================================\n",
            "Found 100 songs for 1994\n",
            "🚀 5/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1994 lyrics: 100%|██████████| 95/95 [00:06<00:00, 15.53song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1994 data in 6.3s - 10 missing\n",
            "\n",
            "========================================\n",
            "Processing 1995\n",
            "========================================\n",
            "Found 100 songs for 1995\n",
            "🚀 10/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1995 lyrics: 100%|██████████| 90/90 [00:05<00:00, 15.21song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1995 data in 6.1s - 17 missing\n",
            "\n",
            "========================================\n",
            "Processing 1996\n",
            "========================================\n",
            "Found 100 songs for 1996\n",
            "🚀 6/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1996 lyrics: 100%|██████████| 94/94 [00:06<00:00, 15.51song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1996 data in 6.5s - 17 missing\n",
            "\n",
            "========================================\n",
            "Processing 1997\n",
            "========================================\n",
            "Found 100 songs for 1997\n",
            "🚀 13/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1997 lyrics: 100%|██████████| 87/87 [00:06<00:00, 14.23song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1997 data in 6.3s - 17 missing\n",
            "\n",
            "========================================\n",
            "Processing 1998\n",
            "========================================\n",
            "Found 100 songs for 1998\n",
            "🚀 10/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1998 lyrics: 100%|██████████| 90/90 [00:05<00:00, 15.00song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1998 data in 6.2s - 14 missing\n",
            "\n",
            "========================================\n",
            "Processing 1999\n",
            "========================================\n",
            "Found 100 songs for 1999\n",
            "🚀 3/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 1999 lyrics: 100%|██████████| 97/97 [00:06<00:00, 15.34song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1999 data in 6.5s - 8 missing\n",
            "\n",
            "========================================\n",
            "Processing 2000\n",
            "========================================\n",
            "Found 100 songs for 2000\n",
            "🚀 5/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2000 lyrics: 100%|██████████| 95/95 [00:07<00:00, 13.29song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2000 data in 7.4s - 7 missing\n",
            "\n",
            "========================================\n",
            "Processing 2001\n",
            "========================================\n",
            "Found 100 songs for 2001\n",
            "🚀 7/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2001 lyrics: 100%|██████████| 93/93 [00:06<00:00, 14.93song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2001 data in 6.5s - 7 missing\n",
            "\n",
            "========================================\n",
            "Processing 2002\n",
            "========================================\n",
            "Found 100 songs for 2002\n",
            "🚀 6/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2002 lyrics: 100%|██████████| 94/94 [00:05<00:00, 15.93song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2002 data in 6.2s - 6 missing\n",
            "\n",
            "========================================\n",
            "Processing 2003\n",
            "========================================\n",
            "Found 100 songs for 2003\n",
            "🚀 3/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2003 lyrics: 100%|██████████| 97/97 [00:05<00:00, 16.34song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2003 data in 6.5s - 7 missing\n",
            "\n",
            "========================================\n",
            "Processing 2004\n",
            "========================================\n",
            "Found 100 songs for 2004\n",
            "🚀 8/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2004 lyrics: 100%|██████████| 92/92 [00:05<00:00, 15.88song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2004 data in 6.1s - 5 missing\n",
            "\n",
            "========================================\n",
            "Processing 2005\n",
            "========================================\n",
            "Found 100 songs for 2005\n",
            "🚀 6/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2005 lyrics: 100%|██████████| 94/94 [00:05<00:00, 15.73song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2005 data in 6.2s - 8 missing\n",
            "\n",
            "========================================\n",
            "Processing 2006\n",
            "========================================\n",
            "Found 100 songs for 2006\n",
            "🚀 10/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2006 lyrics: 100%|██████████| 90/90 [00:06<00:00, 14.33song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2006 data in 6.5s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 2007\n",
            "========================================\n",
            "Found 100 songs for 2007\n",
            "🚀 8/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2007 lyrics: 100%|██████████| 92/92 [00:05<00:00, 15.60song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2007 data in 6.1s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 2008\n",
            "========================================\n",
            "Found 100 songs for 2008\n",
            "🚀 9/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2008 lyrics: 100%|██████████| 91/91 [00:05<00:00, 17.52song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2008 data in 5.5s - 4 missing\n",
            "\n",
            "========================================\n",
            "Processing 2009\n",
            "========================================\n",
            "Found 100 songs for 2009\n",
            "🚀 10/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2009 lyrics: 100%|██████████| 90/90 [00:05<00:00, 15.73song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2009 data in 6.3s - 6 missing\n",
            "\n",
            "========================================\n",
            "Processing 2010\n",
            "========================================\n",
            "Found 100 songs for 2010\n",
            "🚀 12/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2010 lyrics: 100%|██████████| 88/88 [00:06<00:00, 14.51song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2010 data in 6.3s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 2011\n",
            "========================================\n",
            "Found 100 songs for 2011\n",
            "🚀 9/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2011 lyrics: 100%|██████████| 91/91 [00:05<00:00, 17.06song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2011 data in 5.6s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 2012\n",
            "========================================\n",
            "Found 100 songs for 2012\n",
            "🚀 8/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2012 lyrics: 100%|██████████| 92/92 [00:05<00:00, 16.50song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2012 data in 5.8s - 4 missing\n",
            "\n",
            "========================================\n",
            "Processing 2013\n",
            "========================================\n",
            "Found 100 songs for 2013\n",
            "🚀 11/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2013 lyrics: 100%|██████████| 89/89 [00:05<00:00, 16.59song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2013 data in 5.6s - 8 missing\n",
            "\n",
            "========================================\n",
            "Processing 2014\n",
            "========================================\n",
            "Found 100 songs for 2014\n",
            "🚀 11/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2014 lyrics: 100%|██████████| 89/89 [00:05<00:00, 16.90song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2014 data in 5.5s - 4 missing\n",
            "\n",
            "========================================\n",
            "Processing 2015\n",
            "========================================\n",
            "Found 100 songs for 2015\n",
            "🚀 8/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2015 lyrics: 100%|██████████| 92/92 [00:06<00:00, 15.13song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2015 data in 6.5s - 13 missing\n",
            "\n",
            "========================================\n",
            "Processing 2016\n",
            "========================================\n",
            "Found 100 songs for 2016\n",
            "🚀 10/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2016 lyrics: 100%|██████████| 90/90 [00:05<00:00, 15.63song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2016 data in 6.0s - 13 missing\n",
            "\n",
            "========================================\n",
            "Processing 2017\n",
            "========================================\n",
            "Found 100 songs for 2017\n",
            "🚀 7/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2017 lyrics: 100%|██████████| 93/93 [00:05<00:00, 16.19song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2017 data in 6.1s - 12 missing\n",
            "\n",
            "========================================\n",
            "Processing 2018\n",
            "========================================\n",
            "Found 100 songs for 2018\n",
            "🚀 13/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2018 lyrics: 100%|██████████| 87/87 [00:05<00:00, 15.42song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2018 data in 5.9s - 11 missing\n",
            "\n",
            "========================================\n",
            "Processing 2019\n",
            "========================================\n",
            "Found 100 songs for 2019\n",
            "🚀 10/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2019 lyrics: 100%|██████████| 90/90 [00:06<00:00, 14.59song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2019 data in 6.5s - 9 missing\n",
            "\n",
            "========================================\n",
            "Processing 2020\n",
            "========================================\n",
            "Found 100 songs for 2020\n",
            "🚀 8/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2020 lyrics: 100%|██████████| 92/92 [00:05<00:00, 15.74song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2020 data in 6.1s - 11 missing\n",
            "\n",
            "========================================\n",
            "Processing 2021\n",
            "========================================\n",
            "Found 100 songs for 2021\n",
            "🚀 7/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2021 lyrics: 100%|██████████| 93/93 [00:05<00:00, 16.28song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2021 data in 6.0s - 8 missing\n",
            "\n",
            "========================================\n",
            "Processing 2022\n",
            "========================================\n",
            "Found 100 songs for 2022\n",
            "🚀 12/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2022 lyrics: 100%|██████████| 88/88 [00:05<00:00, 15.27song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2022 data in 6.2s - 5 missing\n",
            "\n",
            "========================================\n",
            "Processing 2023\n",
            "========================================\n",
            "Found 100 songs for 2023\n",
            "🚀 13/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2023 lyrics: 100%|██████████| 87/87 [00:06<00:00, 14.23song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2023 data in 6.4s - 8 missing\n",
            "\n",
            "========================================\n",
            "Processing 2024\n",
            "========================================\n",
            "Found 100 songs for 2024\n",
            "🚀 18/100 lyrics from cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching 2024 lyrics: 100%|██████████| 82/82 [00:05<00:00, 14.26song/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 2024 data in 6.0s - 5 missing\n",
            "\n",
            "Saved 1088 missing entries to log\n",
            "1959: 42 missing lyrics\n",
            "1960: 36 missing lyrics\n",
            "1961: 29 missing lyrics\n",
            "1962: 29 missing lyrics\n",
            "1963: 42 missing lyrics\n",
            "1964: 40 missing lyrics\n",
            "1965: 29 missing lyrics\n",
            "1966: 42 missing lyrics\n",
            "1967: 33 missing lyrics\n",
            "1968: 31 missing lyrics\n",
            "1970: 32 missing lyrics\n",
            "1971: 42 missing lyrics\n",
            "1972: 31 missing lyrics\n",
            "1973: 28 missing lyrics\n",
            "1974: 22 missing lyrics\n",
            "1975: 28 missing lyrics\n",
            "1976: 20 missing lyrics\n",
            "1977: 22 missing lyrics\n",
            "1978: 10 missing lyrics\n",
            "1979: 23 missing lyrics\n",
            "1980: 22 missing lyrics\n",
            "1981: 21 missing lyrics\n",
            "1982: 24 missing lyrics\n",
            "1983: 10 missing lyrics\n",
            "1984: 15 missing lyrics\n",
            "1985: 15 missing lyrics\n",
            "1986: 9 missing lyrics\n",
            "1987: 9 missing lyrics\n",
            "1988: 9 missing lyrics\n",
            "1989: 12 missing lyrics\n",
            "1990: 8 missing lyrics\n",
            "1991: 16 missing lyrics\n",
            "1992: 9 missing lyrics\n",
            "1993: 18 missing lyrics\n",
            "1994: 10 missing lyrics\n",
            "1995: 17 missing lyrics\n",
            "1996: 17 missing lyrics\n",
            "1997: 17 missing lyrics\n",
            "1998: 14 missing lyrics\n",
            "1999: 8 missing lyrics\n",
            "2000: 7 missing lyrics\n",
            "2001: 7 missing lyrics\n",
            "2002: 6 missing lyrics\n",
            "2003: 7 missing lyrics\n",
            "2004: 5 missing lyrics\n",
            "2005: 8 missing lyrics\n",
            "2006: 9 missing lyrics\n",
            "2007: 9 missing lyrics\n",
            "2008: 4 missing lyrics\n",
            "2009: 6 missing lyrics\n",
            "2010: 9 missing lyrics\n",
            "2011: 9 missing lyrics\n",
            "2012: 4 missing lyrics\n",
            "2013: 8 missing lyrics\n",
            "2014: 4 missing lyrics\n",
            "2015: 13 missing lyrics\n",
            "2016: 13 missing lyrics\n",
            "2017: 12 missing lyrics\n",
            "2018: 11 missing lyrics\n",
            "2019: 9 missing lyrics\n",
            "2020: 11 missing lyrics\n",
            "2021: 8 missing lyrics\n",
            "2022: 5 missing lyrics\n",
            "2023: 8 missing lyrics\n",
            "2024: 5 missing lyrics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🗜️ Zipping Billboard Hot 100 CSV Files\n",
        "The function **zip_csv_files()** automates the process of compressing individual Billboard Hot 100 CSV files into a single ZIP archive named hot100_data.zip. It checks for the existence of each yearly CSV file (e.g., hot100_2000.csv) and adds it to the archive if found.\n",
        "\n",
        "The zipped file is useful for efficiently downloading and transferring the complete dataset between different stages of the project (e.g., from the Data Collection stage to pre-processing and analysis).\n",
        "\n"
      ],
      "metadata": {
        "id": "Eg6wUSIlr9q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def zip_csv_files(start_year=1959, end_year=2024, output_zip='hot100_data_all_years.zip'):\n",
        "    with zipfile.ZipFile(output_zip, 'w') as zipf:\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            filename = f\"hot100_{year}.csv\"\n",
        "            if os.path.exists(filename):\n",
        "                zipf.write(filename)\n",
        "    print(f\"✅ All CSV files zipped to {output_zip}\")\n",
        "\n",
        "# Create zip file\n",
        "zip_csv_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAjFMOVjrrmV",
        "outputId": "75eae956-51e1-4e9e-d3c2-13cf3edc58f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All CSV files zipped to hot100_data_all_years.zip\n"
          ]
        }
      ]
    }
  ]
}